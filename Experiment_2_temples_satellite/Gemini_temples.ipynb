{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juergenlandauer/FoundationModelsArchaeology/blob/main/Experiment_2_temples_satellite/Gemini_temples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic site detection in satellite and LiDAR images with Gemini by Google\n",
        "\n",
        "Author: Juergen Landauer (juergen AT landauer-ai.de)\n",
        "\n",
        "To start, first go to the \"Input parameters\" section below and review or (optionally) adjust parameters. Then run the entire Notebook by choosing Runtime->Run all in the menu above.\n"
      ],
      "metadata": {
        "id": "2dLqajW6fpzX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key and install the Gemini Python SDK\n",
        "\n",
        "To access Gemini, you need to provide your Google Gemini API key. Follow these steps:\n",
        "\n",
        "- register with Google (also works with your Gmail account\n",
        "- Login here and get your API key: (https://aistudio.google.com/apikey)\n",
        "- Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘).\n",
        "- Store Google API key under the name `GOOGLE_API_KEY`.\n",
        "\n",
        "Details are found here: https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq google-generativeai\n",
        "!pip install -Uq rvt-py rasterio"
      ],
      "metadata": {
        "id": "RsSHrM4ymXA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.colab import userdata\n",
        "from google.genai import types\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input parameters\n",
        "\n",
        "Review all parameters in this section and (optionally) adjust them on the right side. For example, you can upload your own input zip file by providing an URL."
      ],
      "metadata": {
        "id": "_Yr1IaV0_Lk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Demo with temples from Cambodia in satellite imagery from Microsoft Bing\n",
        "Feel free to replace this with your own imagery by providing a download URL (e.g. from Google Drive)\n",
        "\n",
        "Note that the ZIP file must contain two sub-folders called \"sites\" and \"nonsites\", resp. Each folder must then contain images of sites or samples of other landscape (non-sites)"
      ],
      "metadata": {
        "id": "XiarFXMU6rmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_ZIP_URL_NONSITES = 'https://www.dropbox.com/scl/fi/q0mddolngvou51vyojhii/NonsitesKhmer.zip?rlkey=d718q7vonuh1g07yhajn4a8h0&dl=0'\n",
        "INPUT_ZIP_URL_SITES    = 'unavailable'"
      ],
      "metadata": {
        "id": "eQAgLtOrMrsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The text 'prompt' sent to the Foundation Model.\n",
        "\n",
        "Play with different variations of the text and don't forget to include the object type you are looking for."
      ],
      "metadata": {
        "id": "y_7102DV6545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Temples\n",
        "PROMPT = \"\"\"\n",
        "You are analyzing a satellite image that may contain archaeological features from Cambodia, such as ancient Khmer Buddhist temples or other ancient man-made structures.\n",
        "\n",
        "For each distinct object or feature, return the following in JSON format:\n",
        "\n",
        "Object Type â€” classify the object (e.g., temple, reservoir, unknown).\n",
        "\n",
        "Confidence Score â€” your estimated probability (%) that the classification is correct.\n",
        "\n",
        "Bounding Box â€” provide coordinates in the format [x_min, y_min, x_max, y_max]. Make sure the bounding box tightly encompasses the object.\n",
        "\n",
        "Reason - textually explain why you think the given object is found.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gwyEPVy4NIXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text response from the AI is sometimes ambiguous. If you only (or \"strictly\") want to see certain types of responses, then keep this to True and provide a list of keywords you want to see in the output. Make sure you do not mess up the list syntax."
      ],
      "metadata": {
        "id": "xP3C63n08MzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRICT_RESPONSE_FILTERING = True # @param ['True', 'False']\n",
        "\n",
        "FILTER_KEYWORDS = [\"temple\", \"moat\"]  # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "1fnFowtk0GyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the model we are using. Usually it is not required to change this."
      ],
      "metadata": {
        "id": "CNhvfGftlOAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID=\"gemini-2.0-flash\" # @param [\"gemini-2.5-flash-preview-05-20\",\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}\n",
        "\n",
        "# here we determine the RPM of these models (RPM = Requests Per Minute)\n",
        "if \"lite\" in MODEL_ID:           RPM = 30\n",
        "elif \"exp\" in MODEL_ID: RPM = 10\n",
        "elif \"preview\" in MODEL_ID:      RPM = 10\n",
        "else:                            RPM = 15 # \"flash\"\n",
        "\n",
        "RPM"
      ],
      "metadata": {
        "id": "BgU53fR9wFIl",
        "outputId": "d925c5f0-acdb-41cb-f06f-a20f44943a48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you have a paid subscription, the RPM can be much higher\n",
        "RPM = 1000"
      ],
      "metadata": {
        "id": "yNhtXPBErb68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you encounter performance issues, consider setting RESIZE to True, as it halves each image dimension"
      ],
      "metadata": {
        "id": "mdaXZ57lrRcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE = False # @param ['True', 'False']"
      ],
      "metadata": {
        "id": "hHRWZSqBH61A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We load the data and unzip it into the directory 'input'"
      ],
      "metadata": {
        "id": "d5T9IqkTHa_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input output file.zip\n",
        "!mkdir -p input/nonsites input/sites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_NONSITES\"\n",
        "!unzip -q file.zip -d input/nonsites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_SITES\"\n",
        "!unzip -q file.zip -d input/sites"
      ],
      "metadata": {
        "id": "Z-bmrrBbHTFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we now import some libraries"
      ],
      "metadata": {
        "id": "fYvXD4rvEEQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from osgeo import gdal\n",
        "import cv2 as cv\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from google.colab import files as colabfiles\n",
        "import json\n",
        "import random\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageColor"
      ],
      "metadata": {
        "id": "7G5Uxbp6EDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some utility functions we use"
      ],
      "metadata": {
        "id": "zcxHNk6nmmRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all pixels below -10 and above 1000-min\n",
        "def remove_outliers(image:np.ndarray):\n",
        "    if np.isnan(image).sum() > 0:\n",
        "        print (\"NAN!\", np.isnan(image).sum() )\n",
        "    min_zero = image[image>-10].min()\n",
        "    image[image<=-10] = min_zero\n",
        "    # do we still have extremal values?\n",
        "    mymax = np.max(image)\n",
        "    mymin = np.min(image)\n",
        "    if mymax-mymin>1000:\n",
        "        print (\"outlier removal:\", mymax)\n",
        "        hi = np.percentile(image, 99).min()\n",
        "        image[image>1000+mymin] = hi\n",
        "    return image"
      ],
      "metadata": {
        "id": "yJ_LrKHtS6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rvt.vis\n",
        "def preprocessSnippetHillshade(image: np.array):\n",
        "    image = remove_outliers(image)\n",
        "\n",
        "    pixels = rvt.vis.hillshade(\n",
        "        dem=np.squeeze(image), # remove axis...\n",
        "                sun_azimuth=315,\n",
        "                sun_elevation=45,\n",
        "                resolution_x=1.,\n",
        "                resolution_y=1.,\n",
        "                ve_factor=3, # was 2 !!!!!!\n",
        "                #no_data=dem_no_data\n",
        "            ) # output is float32\n",
        "    #pixels = np.nan_to_num(pixels, copy=True, nan=0.0, posinf=None, neginf=None)# remove NaN\n",
        "    pixels = pixels[np.newaxis,...] # and add axis again\n",
        "\n",
        "    return pixels"
      ],
      "metadata": {
        "id": "BWBOoztOS7BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "#import rvt.default\n",
        "import rvt.vis\n",
        "\n",
        "def preprocessSnippetSLRM(image: np.ndarray):\n",
        "    image = remove_outliers(image)\n",
        "    image = rvt.vis.slrm(dem=np.squeeze(image), # remove axis...\n",
        "                radius_cell=10,\n",
        "                ve_factor=1,\n",
        "                no_data=None\n",
        "    )\n",
        "    #image = image[np.newaxis,...] # and add axis again\n",
        "    mymin, mymax = image.min(), image.max()\n",
        "    image = np.interp(image, (mymin, mymax), (0, 255)).astype(np.uint8)\n",
        "    return image"
      ],
      "metadata": {
        "id": "ZWBES7CdS7Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "def read_hillshade(fpath):\n",
        "  with rio.open(fpath) as t:\n",
        "     img = t.read().squeeze()\n",
        "  img = (preprocessSnippetHillshade(img)*256).astype(np.uint8)\n",
        "  #img = (preprocessSnippetSLRM(img)).astype(np.uint8)\n",
        "  pilimg = PIL.Image.fromarray(img.squeeze()).convert('RGB')\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "L2JEIYlyTA45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read the images as PIL\n",
        "def read_pil(fpath):\n",
        "  pilimg = PIL.Image.open(fpath)\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "Bf1ZbZkvg_mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified from https://github.com/google-gemini/cookbook/blob/main/quickstarts/Spatial_understanding.ipynb\n",
        "# function to plot bounding boxes on images\n",
        "def plot_bounding_boxes(img, noun_phrases_and_positions):\n",
        "    width, height = img.size\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Iterate over the noun phrases and their positions\n",
        "    for i, (noun_phrase, prob, (y1, x1, y2, x2)) in enumerate(\n",
        "        noun_phrases_and_positions):\n",
        "        # Select a color\n",
        "        color = 'green'\n",
        "        if prob >0.85: color = 'red'\n",
        "        else: color = 'blue'\n",
        "\n",
        "        wid = 4\n",
        "        for k in FILTER_KEYWORDS:\n",
        "          if k in noun_phrase:\n",
        "            color = 'yellow'\n",
        "            wid = 8\n",
        "\n",
        "        # Convert normalized coordinates to absolute coordinates\n",
        "        abs_x1 = int(x1/1000 * width)\n",
        "        abs_y1 = int(y1/1000 * height)\n",
        "        abs_x2 = int(x2/1000 * width)\n",
        "        abs_y2 = int(y2/1000 * height)\n",
        "\n",
        "        # Ensure x1 <= x2 and y1 <= y2\n",
        "        abs_x1, abs_x2 = sorted([abs_x1, abs_x2])  # Sort x-coordinates\n",
        "        abs_y1, abs_y2 = sorted([abs_y1, abs_y2])  # Sort y-coordinates\n",
        "\n",
        "        # Draw the bounding box\n",
        "        draw.rectangle( ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=wid)\n",
        "\n",
        "        # Draw the text\n",
        "        draw.text((abs_x1 + 8, abs_y1 + 6), noun_phrase, fill=color)\n",
        "\n",
        "    # Display the image\n",
        "    img.show()"
      ],
      "metadata": {
        "id": "Pw7UfuMZPL47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# process folder"
      ],
      "metadata": {
        "id": "hqncD_OCLXnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sites = sorted(glob('./input/sites/**/*.*', recursive=True))\n",
        "nonsites = sorted(glob('./input/nonsites/**/*.*', recursive=True))\n",
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "hh2zNw_MK6-s",
        "outputId": "e26b9839-e087-4220-f675-5cb0a37296f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment below if you want to try just a small sample of MAX_N for each class\n",
        "import random\n",
        "MAX_Sites = 20\n",
        "MAX_Nonsites = 100\n",
        "\n",
        "#sites = random.sample(sites, MAX_Sites)\n",
        "#nonsites = random.sample(nonsites, MAX_Nonsites)\n",
        "\n",
        "#sites = sites[0:MAX_Sites]\n",
        "#nonsites = nonsites[0:MAX_Nonsites]"
      ],
      "metadata": {
        "id": "X14BfYxwAAHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "qEWbSwtB3D1k",
        "outputId": "bdce0275-cfe5-430a-daa3-7588015bcf57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the Gemini output format of a 'Detection'\n",
        "from pydantic import BaseModel, TypeAdapter\n",
        "class Detection(BaseModel):\n",
        "  detection_type: str\n",
        "  probability: float\n",
        "  bbox: list[int]\n",
        "  reason: str\n",
        "\n",
        "# Define the schema for a list of Detection objects\n",
        "list_detection_schema = {\n",
        "    \"type\": \"array\",\n",
        "    \"items\": Detection.model_json_schema()\n",
        "}"
      ],
      "metadata": {
        "id": "4DpEbr7-qMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualization function selecction"
      ],
      "metadata": {
        "id": "u4tnNyXXnM9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizeFN = read_hillshade\n",
        "visualizeFN = read_pil"
      ],
      "metadata": {
        "id": "oGPJt-aXFQpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing all files with Gemini"
      ],
      "metadata": {
        "id": "6Sg3gTZv4w_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!mkdir output output/FN output/TP output/FP output/TN"
      ],
      "metadata": {
        "id": "I-tCniW3kGXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure parameters\n",
        "TEMPERATURE = 1.0\n",
        "#TEMPERATURE = 0.7\n",
        "#TEMPERATURE = 0.3"
      ],
      "metadata": {
        "id": "mjbCMrfNI_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "#files = nonsites"
      ],
      "metadata": {
        "id": "dHVx-LLwAk_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./output/phrases.txt', 'w') as docfile:\n",
        "  TP, FP, FN, TN = 0, 0, 0, 0\n",
        "\n",
        "  for fpath in tqdm(files):\n",
        "      img = visualizeFN(fpath)\n",
        "      if RESIZE:\n",
        "            new_size = (img.width // 2, img.height // 2)\n",
        "            img = img.resize(new_size)\n",
        "\n",
        "      #img = img.convert('L')\n",
        "      img.save('temp.png')\n",
        "\n",
        "      with open('temp.png', 'rb') as f:\n",
        "        image_bytes = f.read()\n",
        "\n",
        "      # Construct the contents list with proper part structure\n",
        "      contents = [\n",
        "        PROMPT,\n",
        "        types.Part.from_bytes(\n",
        "        data=image_bytes,\n",
        "        mime_type='image/png',),\n",
        "          #{'text': PROMPT},  # Text part for the prompt\n",
        "      ]\n",
        "\n",
        "      retries = 20 # Number of retries\n",
        "      for attempt in range(retries):\n",
        "          try:\n",
        "              response = client.models.generate_content(model = MODEL_ID,\n",
        "                  contents = contents,\n",
        "                  config={'response_mime_type': 'application/json',\n",
        "                          'response_schema': list_detection_schema,\n",
        "                          'temperature' : TEMPERATURE,\n",
        "                  },\n",
        "                  #request_options={'timeout': 10}\n",
        "              )\n",
        "              break # If successful, break the retry loop\n",
        "          except Exception as e:\n",
        "              if e.code == 503 and attempt < retries - 1:\n",
        "                  print(f\"ServerError 503: Model overloaded. Retrying in 10 seconds (Attempt {attempt + 1}/{retries})...\")\n",
        "                  time.sleep(15)\n",
        "              else:\n",
        "                  print (\"Error==>\",e)\n",
        "                  raise # Re-raise the exception if not a 503 error or no retries left\n",
        "\n",
        "      print('________________________________________________________')\n",
        "      print(fpath, \"-- response:\", response.text)\n",
        "\n",
        "      objects = json.loads(response.text)\n",
        "\n",
        "      # results visualization\n",
        "      img = visualizeFN(fpath)\n",
        "      phrases_boxes = []\n",
        "      for item in objects: # for each detection\n",
        "        if 'probability' in item:\n",
        "            prob = item['probability']\n",
        "        else: prob = 0.\n",
        "        #if prob < 0.9: continue # not a valid detection\n",
        "        detection_type = item['detection_type']\n",
        "        reason = item['reason']\n",
        "        if STRICT_RESPONSE_FILTERING and any(element in detection_type for element in FILTER_KEYWORDS):\n",
        "            bbox = item['bbox']\n",
        "            print (detection_type, prob, bbox)\n",
        "            phrases_boxes += [(detection_type+\"_\"+str(prob), float(prob), bbox)]\n",
        "\n",
        "      if phrases_boxes != []:\n",
        "        plot_bounding_boxes(img, noun_phrases_and_positions=phrases_boxes)\n",
        "        if 'nonsites' in fpath:\n",
        "          FN += 1;p=\"FN\"\n",
        "        else:\n",
        "          TP += 1;p=\"TP\"\n",
        "      else:\n",
        "        if 'nonsites' in fpath:\n",
        "          TN += 1;p=\"TN\"\n",
        "        else:\n",
        "          FP += 1;p=\"FP\"\n",
        "\n",
        "      filename = Path(fpath).name\n",
        "      img.save(Path('output')/Path(p)/filename)\n",
        "      display(img.resize(size=(384, 384)))\n",
        "      docfile.write(filename + \":\" + str(objects) + os.linesep)\n",
        "      print(TP, FP, FN, TN)\n",
        "      time.sleep(60//RPM + 0.2) # sleep to meet RPM limit (requests per minute)"
      ],
      "metadata": {
        "id": "uU21koneAf9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F1 = 2*TP/(2*TP+FP+FN)\n",
        "print (TP, FP, FN, TN)\n",
        "print (\"TPR=\", TP/len(sites), \"FPR=\", FP/len(nonsites))\n",
        "print (\"********* F1:\", F1, \" *************\")\n",
        "\n",
        "with open('./output/phrases.txt', 'a') as docfile:\n",
        "  docfile.write(f\"---RESULTS------{os.linesep}\")\n",
        "  docfile.write(f\"TP, FP, FN, TN={TP}, {FP}, {FN}, {TN}{os.linesep}\")\n",
        "  docfile.write(f\"F1={F1}{os.linesep}\")"
      ],
      "metadata": {
        "id": "Ucbfx_IaMgrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export results for download\n",
        "We now open a file download dialog for the output.zip. Simply store the output in your local computer. Done :-)\n",
        "\n",
        "output.zip contains all images with bounding box annotations and a file phrases.txt containing the original response from Gemini.\n",
        "\n"
      ],
      "metadata": {
        "id": "bEriipIF22Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output"
      ],
      "metadata": {
        "id": "wJNheETmcYqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colabfiles.download('outputTemples.zip')"
      ],
      "metadata": {
        "id": "AE1-K5HR4Za7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHracSEI0kFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}