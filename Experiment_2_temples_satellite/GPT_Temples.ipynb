{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juergenlandauer/FoundationModelsArchaeology/blob/main/Experiment_2_temples_satellite/GPT_Temples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic site detection in satellite and LiDAR images with Gemini by Google\n",
        "\n",
        "Author: Juergen Landauer (juergen AT landauer-ai.de)\n",
        "\n",
        "To start, first go to the \"Input parameters\" section below and review or (optionally) adjust parameters. Then run the entire Notebook by choosing Runtime->Run all in the menu above.\n"
      ],
      "metadata": {
        "id": "2dLqajW6fpzX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key and install the Open AI Python SDK\n",
        "\n",
        "To access GPT-4, you need to provide your OpenAI API key. Follow these steps:\n",
        "\n",
        "- register with Open AI\n",
        "- Open your [`OpenAI Settings`](https://platform.openai.com/settings) page. Click `User API keys` then `Create new secret key` to generate new token.\n",
        "Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘).\n",
        "- Store OpenAI API key under the name `OPENAI_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai\n",
        "!pip install -Uq rvt-py rasterio"
      ],
      "metadata": {
        "id": "RsSHrM4ymXA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input parameters\n",
        "\n",
        "Review all parameters in this section and (optionally) adjust them on the right side. For example, you can upload your own input zip file by providing an URL."
      ],
      "metadata": {
        "id": "_Yr1IaV0_Lk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Demo with temples from Cambodia in satellite imagery from Microsoft Bing\n",
        "\n",
        "Feel free to replace this with your own imagery by providing a download URL (e.g. from Google Drive)\n",
        "\n",
        "Note that the ZIP file must contain two sub-folders called \"sites\" and \"nonsites\", resp. Each folder must then contain images of sites or samples of other landscape (non-sites)"
      ],
      "metadata": {
        "id": "XiarFXMU6rmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temples"
      ],
      "metadata": {
        "id": "sayH7Ql4-N6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_ZIP_URL_NONSITES = 'unavailable'\n",
        "INPUT_ZIP_URL_SITES    = 'unavailable'"
      ],
      "metadata": {
        "id": "Th1vwoti4J4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The text 'prompt' sent to the Foundation Model.\n",
        "\n",
        "Play with different variations of the text and don't forget to include the object type you are looking for."
      ],
      "metadata": {
        "id": "y_7102DV6545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Castles\n",
        "PROMPT = \"\"\"\n",
        "You are analyzing a satellite image that may contain archaeological features from Germany, such as castles, ruins, or other ancient man-made structures.\n",
        "\n",
        "Important Note: The majority of images will likely contain no archaeological features at all.\n",
        "Therefore, avoid making detections unless there is strong, high-confidence evidence above 75 percent.\n",
        "\n",
        "For each distinct object or feature only if confidently detected, return the following in JSON format:\n",
        "\n",
        "Object Type â€” classify the object (e.g., enclosure, hillfort, natural formation).\n",
        "\n",
        "Confidence Score â€” your estimated probability (%) that the classification is correct.\n",
        "\n",
        "Bounding Box â€” provide coordinates in the format [x_min, y_min, x_max, y_max]. Make sure the bounding box tightly encompasses the object.\n",
        "\n",
        "Reason - textually explain why you think the given object is found.\n",
        "\n",
        "If no archaeological features are confidently detected, return an empty list\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gwyEPVy4NIXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Temples\n",
        "PROMPT = \"\"\"\n",
        "You are analyzing a satellite image that may contain archaeological features from Cambodia, such as ancient Buddhist temples or other ancient man-made structures.\n",
        "\n",
        "For each distinct object or feature, return the following in JSON format:\n",
        "\n",
        "Object Type â€” classify the object (e.g., temple, reservoir, moat, unknown).\n",
        "\n",
        "Confidence Score â€” your estimated probability (%) that the classification is correct.\n",
        "\n",
        "Bounding Box â€” provide coordinates in the format [x_min, y_min, x_max, y_max]. Make sure the bounding box tightly encompasses the object.\n",
        "\n",
        "Reason - textually explain why you think the given object is found.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fd3cJIizKLL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text response from the AI is sometimes ambiguous. If you only (or \"strictly\") want to see certain types of responses, then keep this to True and provide a list of keywords you want to see in the output. Make sure you do not mess up the list syntax."
      ],
      "metadata": {
        "id": "xP3C63n08MzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRICT_RESPONSE_FILTERING = True # @param ['True', 'False']\n",
        "\n",
        "FILTER_KEYWORDS = [\"castle\", \"ruin\", \"enclosure\", \"hillfort\"]  # @param {\"allow-input\":true}\n",
        "FILTER_KEYWORDS = [\"temple\", \"reservoir\", \"moat\"]  # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "1fnFowtk0GyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the model we are using. Usually it is not required to change this."
      ],
      "metadata": {
        "id": "CNhvfGftlOAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4.1-mini\" # @param [\"gpt-4.1-mini\",\"gpt-4.1-nano\", \"gpt-4.1\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "BgU53fR9wFIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you encounter performance issues, consider setting RESIZE to True, as it halves each image dimension"
      ],
      "metadata": {
        "id": "JcT4dSrJPlgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE = False # @param ['True', 'False']"
      ],
      "metadata": {
        "id": "t6XfUKypPhGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We load the data and unzip it into the directory 'input'"
      ],
      "metadata": {
        "id": "d5T9IqkTHa_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input output file.zip\n",
        "!mkdir -p input/nonsites input/sites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_NONSITES\"\n",
        "!unzip -q file.zip -d input/nonsites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_SITES\"\n",
        "!unzip -q file.zip -d input/sites"
      ],
      "metadata": {
        "id": "Z-bmrrBbHTFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we now import some libraries"
      ],
      "metadata": {
        "id": "fYvXD4rvEEQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from osgeo import gdal\n",
        "import cv2 as cv\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "from google.colab import files as colabfiles\n",
        "import json\n",
        "import random\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageColor, ImageFont\n",
        "import re"
      ],
      "metadata": {
        "id": "7G5Uxbp6EDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some utility functions we use"
      ],
      "metadata": {
        "id": "zcxHNk6nmmRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all pixels below -10 and above 1000-min\n",
        "def remove_outliers(image:np.ndarray):\n",
        "    if np.isnan(image).sum() > 0:\n",
        "        print (\"NAN!\", np.isnan(image).sum() )\n",
        "    min_zero = image[image>-10].min()\n",
        "    image[image<=-10] = min_zero\n",
        "    # do we still have extremal values?\n",
        "    mymax = np.max(image)\n",
        "    mymin = np.min(image)\n",
        "    if mymax-mymin>1000:\n",
        "        print (\"outlier removal:\", mymax)\n",
        "        hi = np.percentile(image, 99).min()\n",
        "        image[image>1000+mymin] = hi\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "yJ_LrKHtS6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image\n",
        "import base64 # Import the base64 module\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "aTPvkFEqmeN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rvt.vis\n",
        "def preprocessSnippetHillshade(image: np.array):\n",
        "    image = remove_outliers(image)\n",
        "\n",
        "    pixels = rvt.vis.hillshade(\n",
        "        dem=np.squeeze(image), # remove axis...\n",
        "                sun_azimuth=315,\n",
        "                sun_elevation=45,\n",
        "                resolution_x=1.,\n",
        "                resolution_y=1.,\n",
        "                ve_factor=3, # was 2 !!!!!!\n",
        "                #no_data=dem_no_data\n",
        "            ) # output is float32\n",
        "    #pixels = np.nan_to_num(pixels, copy=True, nan=0.0, posinf=None, neginf=None)# remove NaN\n",
        "    pixels = pixels[np.newaxis,...] # and add axis again\n",
        "\n",
        "    return pixels"
      ],
      "metadata": {
        "id": "BWBOoztOS7BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "#import rvt.default\n",
        "import rvt.vis\n",
        "\n",
        "def preprocessSnippetSLRM(image: np.ndarray):\n",
        "    image = remove_outliers(image)\n",
        "    image = rvt.vis.slrm(dem=np.squeeze(image), # remove axis...\n",
        "                radius_cell=10,\n",
        "                ve_factor=1,\n",
        "                no_data=None\n",
        "    )\n",
        "    #image = image[np.newaxis,...] # and add axis again\n",
        "    mymin, mymax = image.min(), image.max()\n",
        "    image = np.interp(image, (mymin, mymax), (0, 255)).astype(np.uint8)\n",
        "    return image"
      ],
      "metadata": {
        "id": "ZWBES7CdS7Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "import PIL\n",
        "def read_hillshade(fpath):\n",
        "  with rio.open(fpath) as t:\n",
        "     img = t.read().squeeze()\n",
        "  img = (preprocessSnippetHillshade(img)*256).astype(np.uint8)\n",
        "  #img = (preprocessSnippetSLRM(img)).astype(np.uint8)\n",
        "  pilimg = PIL.Image.fromarray(img.squeeze()).convert('RGB')\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "L2JEIYlyTA45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read the images as PIL\n",
        "def read_pil(fpath):\n",
        "  pilimg = PIL.Image.open(fpath)\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "Bf1ZbZkvg_mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot bounding boxes on images\n",
        "def plot_bounding_boxes(img, results):\n",
        "    width, height = img.size\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    fpath='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'\n",
        "    fontsize = 24\n",
        "    font = ImageFont.truetype(fpath, fontsize)\n",
        "\n",
        "    noun_phrase, prob, bbox = results\n",
        "\n",
        "    if len(bbox) != 4: return # nothing found\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    # Ensure x1 <= x2 and y1 <= y2\n",
        "    x1, x2 = sorted([x1, x2])  # Sort x-coordinates\n",
        "    y1, y2 = sorted([y1, y2])  # Sort y-coordinates\n",
        "\n",
        "    color = 'yellow'\n",
        "    # Draw the bounding box\n",
        "    draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=4)\n",
        "    # Draw the text\n",
        "    draw.text((x1 + 8, y1 + 6), noun_phrase+\" \"+str(prob), fill=color, font=font)"
      ],
      "metadata": {
        "id": "Pw7UfuMZPL47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# process folder"
      ],
      "metadata": {
        "id": "hqncD_OCLXnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sites = sorted(glob('./input/sites/**/*.*', recursive=True))\n",
        "nonsites = sorted(glob('./input/nonsites/**/*.*', recursive=True))\n",
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "hh2zNw_MK6-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you want to try just a small sample of MAX_N for each class\n",
        "import random\n",
        "MAX_Sites = 20\n",
        "MAX_Nonsites = 40\n",
        "\n",
        "#sites = random.sample(sites, MAX_Sites)\n",
        "#nonsites = random.sample(nonsites, MAX_Nonsites)\n",
        "\n",
        "#sites = sites[0:MAX_Sites]\n",
        "#nonsites = nonsites[0:MAX_Nonsites]"
      ],
      "metadata": {
        "id": "X14BfYxwAAHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "qEWbSwtB3D1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the Gemini output format of a 'Detection'\n",
        "from pydantic import BaseModel, TypeAdapter\n",
        "class Detection(BaseModel):\n",
        "  detection_type: str\n",
        "  probability: float\n",
        "  bbox: list[int]\n",
        "  reason: str"
      ],
      "metadata": {
        "id": "4DpEbr7-qMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizeFN = read_hillshade\n",
        "visualizeFN = read_pil"
      ],
      "metadata": {
        "id": "oGPJt-aXFQpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing all files with GPT"
      ],
      "metadata": {
        "id": "6Sg3gTZv4w_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!mkdir output output/FN output/TP output/FP output/TN"
      ],
      "metadata": {
        "id": "I-tCniW3kGXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure parameters\n",
        "#TEMPERATURE = 1.0\n",
        "#TEMPERATURE = 0.7\n",
        "TEMPERATURE = 0.3"
      ],
      "metadata": {
        "id": "mjbCMrfNI_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "#files = nonsites"
      ],
      "metadata": {
        "id": "dHVx-LLwAk_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "\n",
        "with open('./output/phrases.txt', 'w') as docfile:\n",
        "  TP, FP, FN, TN = 0, 0, 0, 0\n",
        "  for fpath in tqdm(files):\n",
        "    img = read_pil(fpath)\n",
        "    new_size = (img.width // 2, img.height // 2)\n",
        "    img2 = img.copy().resize(new_size) if RESIZE else img\n",
        "\n",
        "    img2.save('./tmp.png')\n",
        "    base64_image = encode_image(\"./tmp.png\")\n",
        "    print('________________________________________________________')\n",
        "\n",
        "    response_format = Detection\n",
        "    for attempt in range(10):\n",
        "      try:\n",
        "        response = client.responses.create(\n",
        "          model = MODEL,\n",
        "          temperature = 0.3,\n",
        "          input=[{\n",
        "             \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": PROMPT},\n",
        "                {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "          },],}],\n",
        "          text={\n",
        "            \"format\": {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"name\": \"Detection\",\n",
        "              \"schema\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                      \"detection_type\": {\n",
        "                          \"type\": \"string\"},\n",
        "                      \"probability\": {\n",
        "                          \"type\": \"number\"\n",
        "                      },\n",
        "                      \"bbox\": {\n",
        "                          \"type\": \"array\",\n",
        "                          \"items\": {\n",
        "                              \"type\": \"number\"}\n",
        "                      },\n",
        "                      \"reason\": {\"type\": \"string\"},\n",
        "                  },\n",
        "                  \"required\": [\"detection_type\", \"probability\", \"bbox\", \"reason\"],\n",
        "                  \"additionalProperties\": False\n",
        "              },\n",
        "              \"strict\":True\n",
        "            },},)\n",
        "        if response.output_text:\n",
        "          break # we got through!\n",
        "        #else:\n",
        "        #  print (\"!no output - retry\")\n",
        "      except Exception as e:\n",
        "        print (e);sleep(5);continue\n",
        "      else:\n",
        "        print (\"next attempt\", attempt)\n",
        "\n",
        "    outlist = re.findall(r'({.*?})', response.output_text, re.DOTALL)\n",
        "\n",
        "    FOUND = False\n",
        "    for out in outlist:\n",
        "      try:\n",
        "        ret = json.loads(out)\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Could not decode JSON object: {out}\")\n",
        "        print(f\"Error: {e}\")\n",
        "      except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing: {out}\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "      if STRICT_RESPONSE_FILTERING:\n",
        "        if any(element in ret['detection_type'].lower() for element in FILTER_KEYWORDS) and float(ret['probability']) >= 0.75:\n",
        "          FOUND = True\n",
        "          plot_bounding_boxes(img, (ret['detection_type'],ret['probability'], ret['bbox']))\n",
        "      else:\n",
        "        p = \"\"\n",
        "\n",
        "    if FOUND:\n",
        "      if 'nonsites' in fpath: FP += 1; p=\"FP\"\n",
        "      else: TP += 1;p=\"TP\"\n",
        "    else:\n",
        "      if 'nonsites' in fpath: TN += 1;p=\"TN\"\n",
        "      else: FN += 1;p=\"FN\"\n",
        "\n",
        "    print (fpath, \"------\", FOUND, \"---\", ret)\n",
        "    display(img.resize(size=(384,384)))\n",
        "\n",
        "    filename = Path(fpath).name\n",
        "    img.save(Path('output')/Path(p)/filename)\n",
        "    docfile.write(\"--- \" + fpath + \":\" + json.dumps(outlist) + os.linesep)\n",
        "    print(\"TP, FP, FN, TN=\", TP, FP, FN, TN, \"(\",TP+FN,\")\")\n",
        "    sleep(1.5)"
      ],
      "metadata": {
        "id": "RDeraYDimtN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F1 = 2*TP/(2*TP+FP+FN)\n",
        "print (TP, FP, FN, TN)\n",
        "print (\"TPR=\", TP/len(sites), \"FPR=\", FP/len(nonsites))\n",
        "print (\"********* F1:\", F1, \" *************\")\n",
        "\n",
        "with open('./output/phrases.txt', 'a') as docfile:\n",
        "  docfile.write(f\"---RESULTS------{os.linesep}\")\n",
        "  docfile.write(f\"TP, FP, FN, TN={TP}, {FP}, {FN}, {TN}{os.linesep}\")\n",
        "  docfile.write(f\"F1={F1}{os.linesep}\")"
      ],
      "metadata": {
        "id": "Ucbfx_IaMgrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export results for download\n",
        "We now open a file download dialog for the output.zip. Simply store the output in your local computer. Done :-)\n",
        "\n",
        "output.zip contains all images with bounding box annotations and a file phrases.txt containing the original response from Gemini.\n",
        "\n"
      ],
      "metadata": {
        "id": "bEriipIF22Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output"
      ],
      "metadata": {
        "id": "wJNheETmcYqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colabfiles.download('output.zip')"
      ],
      "metadata": {
        "id": "AE1-K5HR4Za7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHracSEI0kFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}