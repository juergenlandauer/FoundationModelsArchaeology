{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juergenlandauer/FoundationModelsArchaeology/blob/main/Experiment_3_Hillforts_LiDAR/GPT_hillforts_Lidar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automatic site detection in satellite and LiDAR images with Gemini by Google\n",
        "\n",
        "Author: Juergen Landauer (juergen AT landauer-ai.de)\n",
        "\n",
        "To start, first go to the \"Input parameters\" section below and review or (optionally) adjust parameters. Then run the entire Notebook by choosing Runtime->Run all in the menu above.\n"
      ],
      "metadata": {
        "id": "2dLqajW6fpzX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key and install the Open AI Python SDK\n",
        "\n",
        "To access GPT-4, you need to provide your OpenAI API key. Follow these steps:\n",
        "\n",
        "- register with Open AI\n",
        "- Open your [`OpenAI Settings`](https://platform.openai.com/settings) page. Click `User API keys` then `Create new secret key` to generate new token.\n",
        "Click `Copy`. This will place your private key in the clipboard.\n",
        "- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘).\n",
        "- Store OpenAI API key under the name `OPENAI_API_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq openai\n",
        "!pip install -Uq rvt-py rasterio"
      ],
      "metadata": {
        "id": "RsSHrM4ymXA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d72bb6a-2293-413a-9b0d-5a3d01de8740"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m755.6/755.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input parameters\n",
        "\n",
        "Review all parameters in this section and (optionally) adjust them on the right side. For example, you can upload your own input zip file by providing an URL."
      ],
      "metadata": {
        "id": "_Yr1IaV0_Lk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Demo with hillforts in LiDAR\n",
        "\n",
        "> Blockzitat einfÃ¼gen\n",
        "\n",
        "\n",
        "Feel free to replace this with your own imagery by providing a download URL (e.g. from Google Drive)\n",
        "\n",
        "Note that the ZIP file must contain two sub-folders called \"sites\" and \"nonsites\", resp. Each folder must then contain images of sites or samples of other landscape (non-sites)"
      ],
      "metadata": {
        "id": "XiarFXMU6rmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hillforts Lidar"
      ],
      "metadata": {
        "id": "QhsMehGZrcdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_ZIP_URL_NONSITES = 'https://www.dropbox.com/scl/fi/tkar49txfsaz8w7xcfweu/EN_nonforts_1000_GeoTiff_raw.zip?rlkey=k4oymy32v0axue9d158jkpr5o&st=vyp0m12o&dl=0'\n",
        "INPUT_ZIP_URL_SITES    = 'https://www.dropbox.com/scl/fi/kv223sslzfgtcctqai390/EN_hillforts_300_GeoTiff_raw.zip?rlkey=lcjh9kzdpe0q2w943z52kvtyy&st=9837ca2c&dl=0'"
      ],
      "metadata": {
        "id": "C65S5980rcpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The text 'prompt' sent to the Foundation Model.\n",
        "\n",
        "Play with different variations of the text and don't forget to include the object type you are looking for."
      ],
      "metadata": {
        "id": "y_7102DV6545"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hillforts\n",
        "PROMPT = \"\"\"\n",
        "You are analyzing a LiDAR image that may contain archaeological features from England, such as enclosures, hillforts, or other ancient man-made structures.\n",
        "\n",
        "For each distinct object or feature only if confidently detected, return the following in JSON format:\n",
        "\n",
        "Object Type â€” classify the object (e.g., enclosure, hillfort, natural formation, unknown).\n",
        "\n",
        "Confidence Score â€” your estimated probability (%) that the classification is correct.\n",
        "\n",
        "Bounding Box â€” provide coordinates in the format [x_min, y_min, x_max, y_max]. Make sure the bounding box tightly encompasses the object.\n",
        "\n",
        "Reason - textually explain why you think the given object is found.\n",
        "\n",
        "If no archaeological features are confidently detected, return an empty list\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wba9CNg0rjgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The text response from the AI is sometimes ambiguous. If you only (or \"strictly\") want to see certain types of responses, then keep this to True and provide a list of keywords you want to see in the output. Make sure you do not mess up the list syntax."
      ],
      "metadata": {
        "id": "xP3C63n08MzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STRICT_RESPONSE_FILTERING = True # @param ['True', 'False']\n",
        "\n",
        "#FILTER_KEYWORDS = [\"temple\", \"moat\"]  # @param {\"allow-input\":true}\n",
        "\n",
        "#FILTER_KEYWORDS = [\"castle\", \"ruin\", \"enclosure\", \"hillfort\"]  # @param {\"allow-input\":true}\n",
        "\n",
        "FILTER_KEYWORDS = [\"enclosure\", \"hillfort\"]  # @param {\"allow-input\":true}"
      ],
      "metadata": {
        "id": "1fnFowtk0GyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define the model we are using. Usually it is not required to change this."
      ],
      "metadata": {
        "id": "CNhvfGftlOAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL = \"gpt-4.1-mini\" # @param [\"gpt-4.1-mini\",\"gpt-4.1-nano\", \"gpt-4.1\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "BgU53fR9wFIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you encounter performance issues, consider setting RESIZE to True, as it halves each image dimension"
      ],
      "metadata": {
        "id": "JcT4dSrJPlgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RESIZE = False # @param ['True', 'False']"
      ],
      "metadata": {
        "id": "t6XfUKypPhGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We load the data and unzip it into the directory 'input'"
      ],
      "metadata": {
        "id": "d5T9IqkTHa_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf input output file.zip\n",
        "!mkdir -p input/nonsites input/sites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_NONSITES\"\n",
        "!unzip -q file.zip -d input/nonsites\n",
        "!wget -O file.zip \"$INPUT_ZIP_URL_SITES\"\n",
        "!unzip -q file.zip -d input/sites"
      ],
      "metadata": {
        "id": "Z-bmrrBbHTFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "590692e6-1516-4c7e-9871-57e2205f55eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-11 06:43:37--  https://www.dropbox.com/scl/fi/tkar49txfsaz8w7xcfweu/EN_nonforts_1000_GeoTiff_raw.zip?rlkey=k4oymy32v0axue9d158jkpr5o&st=vyp0m12o&dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com/cd/0/inline/CtQ9x7LeNx9-ELYmPiQJLZNK3MgoFdFOzu5QCvJEGdvlHyq27atp6V-QPJ0OozUtdL0WfdL6grHc8MqKuIyVx_WqWyvQJzDv1-w_ha0PGG6zIIgEeKtRMNpj_iB6n5Ni1-Q/file# [following]\n",
            "--2025-07-11 06:43:39--  https://uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com/cd/0/inline/CtQ9x7LeNx9-ELYmPiQJLZNK3MgoFdFOzu5QCvJEGdvlHyq27atp6V-QPJ0OozUtdL0WfdL6grHc8MqKuIyVx_WqWyvQJzDv1-w_ha0PGG6zIIgEeKtRMNpj_iB6n5Ni1-Q/file\n",
            "Resolving uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com (uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com (uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CtSx0Pwo9MhYR-jBdrsQ0kQCbP-RR4qu3CJebBoPALq2UA374fuOpm88d0gYjsfmIAeL9KIa-ad0eqsMPsHyovarUQ7ZY9UQDjGBarxw4QaEN24L7B4ib8U0x8RUUZCw3hgKtbXLXBQ4oPJTd_KH37S37c4jIkZRAM5efyVAqPkaP54v6JE9fhSQvgNhip7BnD2NTuO-JtCwStQCagki8YX8EWmJLBi206VuAlgJ0vrJN15stnQHNqM1sLuG30YwVMVLWNP8QPoRH-C6ZfCk94O6GfxafolSxA3mKMgMfcDSp8XF0UpySvR5moxLDnhdjv49JKjWPiAWaNvIk278L07JF7Ja65bEoO5QGLV5UAXWNg/file [following]\n",
            "--2025-07-11 06:43:40--  https://uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com/cd/0/inline2/CtSx0Pwo9MhYR-jBdrsQ0kQCbP-RR4qu3CJebBoPALq2UA374fuOpm88d0gYjsfmIAeL9KIa-ad0eqsMPsHyovarUQ7ZY9UQDjGBarxw4QaEN24L7B4ib8U0x8RUUZCw3hgKtbXLXBQ4oPJTd_KH37S37c4jIkZRAM5efyVAqPkaP54v6JE9fhSQvgNhip7BnD2NTuO-JtCwStQCagki8YX8EWmJLBi206VuAlgJ0vrJN15stnQHNqM1sLuG30YwVMVLWNP8QPoRH-C6ZfCk94O6GfxafolSxA3mKMgMfcDSp8XF0UpySvR5moxLDnhdjv49JKjWPiAWaNvIk278L07JF7Ja65bEoO5QGLV5UAXWNg/file\n",
            "Reusing existing connection to uce117b7d3871c58a81fbd209bd6.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1842762631 (1.7G) [application/zip]\n",
            "Saving to: â€˜file.zipâ€™\n",
            "\n",
            "file.zip            100%[===================>]   1.72G  20.4MB/s    in 83s     \n",
            "\n",
            "2025-07-11 06:45:03 (21.1 MB/s) - â€˜file.zipâ€™ saved [1842762631/1842762631]\n",
            "\n",
            "--2025-07-11 06:45:34--  https://www.dropbox.com/scl/fi/kv223sslzfgtcctqai390/EN_hillforts_300_GeoTiff_raw.zip?rlkey=lcjh9kzdpe0q2w943z52kvtyy&st=9837ca2c&dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.66.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.66.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0274a7214f2573705b97695367.dl.dropboxusercontent.com/cd/0/inline/CtSK9D8d0d8E4tCsz1zW2jtJ05AVY6_RgCGWap5VUPtQ4fz3sEonz5aQbie2ydxR30ICNqt7c-yrvSAJ7LjTtahF3ZskF67jDe4ko3NVAylbU4ta2jPL1_qrAMDphwwQp0A/file# [following]\n",
            "--2025-07-11 06:45:36--  https://uc0274a7214f2573705b97695367.dl.dropboxusercontent.com/cd/0/inline/CtSK9D8d0d8E4tCsz1zW2jtJ05AVY6_RgCGWap5VUPtQ4fz3sEonz5aQbie2ydxR30ICNqt7c-yrvSAJ7LjTtahF3ZskF67jDe4ko3NVAylbU4ta2jPL1_qrAMDphwwQp0A/file\n",
            "Resolving uc0274a7214f2573705b97695367.dl.dropboxusercontent.com (uc0274a7214f2573705b97695367.dl.dropboxusercontent.com)... 162.125.66.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to uc0274a7214f2573705b97695367.dl.dropboxusercontent.com (uc0274a7214f2573705b97695367.dl.dropboxusercontent.com)|162.125.66.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CtRSmJt0o0M6bmlB1v53A8Y8vrda6cKtIkQVVGkC_ufc7Tq9DsNIk6onoZHX-nnF7xPpnv4tYw1EP-6B7URyba9o-WBLU0aGj6u39_yBeSctztebWNqUrfW_kkTkIo317IkwUoqvXMEHIiiQYge-gc6RMlNqDpn5YAeSyC2pdbgzhhm3BRKQg9TmyqXK0BcESsfs_NSOgdt05o85RAAlw5nq8swl8nWvwvqkbVNBHPLlw6fnnQQU6uZsqtf9Lo0Z-ZKDoO0qGmjwlTOuAmlF-LIpmB2reyVgl0X-b2sevDkj_5ylHrqcqT8i-gWrI4d55YxvO-612qksiNmTeiZa1Mle9CzoOHLjOmR2otSirGKWdg/file [following]\n",
            "--2025-07-11 06:45:37--  https://uc0274a7214f2573705b97695367.dl.dropboxusercontent.com/cd/0/inline2/CtRSmJt0o0M6bmlB1v53A8Y8vrda6cKtIkQVVGkC_ufc7Tq9DsNIk6onoZHX-nnF7xPpnv4tYw1EP-6B7URyba9o-WBLU0aGj6u39_yBeSctztebWNqUrfW_kkTkIo317IkwUoqvXMEHIiiQYge-gc6RMlNqDpn5YAeSyC2pdbgzhhm3BRKQg9TmyqXK0BcESsfs_NSOgdt05o85RAAlw5nq8swl8nWvwvqkbVNBHPLlw6fnnQQU6uZsqtf9Lo0Z-ZKDoO0qGmjwlTOuAmlF-LIpmB2reyVgl0X-b2sevDkj_5ylHrqcqT8i-gWrI4d55YxvO-612qksiNmTeiZa1Mle9CzoOHLjOmR2otSirGKWdg/file\n",
            "Reusing existing connection to uc0274a7214f2573705b97695367.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 516911625 (493M) [application/zip]\n",
            "Saving to: â€˜file.zipâ€™\n",
            "\n",
            "file.zip            100%[===================>] 492.96M  15.0MB/s    in 34s     \n",
            "\n",
            "2025-07-11 06:46:12 (14.4 MB/s) - â€˜file.zipâ€™ saved [516911625/516911625]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### we now import some libraries"
      ],
      "metadata": {
        "id": "fYvXD4rvEEQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from osgeo import gdal\n",
        "import cv2 as cv\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "from time import sleep\n",
        "from tqdm import tqdm\n",
        "from google.colab import files as colabfiles\n",
        "import json\n",
        "import random\n",
        "import io\n",
        "from PIL import Image, ImageDraw, ImageColor, ImageFont\n",
        "import re"
      ],
      "metadata": {
        "id": "7G5Uxbp6EDEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Some utility functions we use"
      ],
      "metadata": {
        "id": "zcxHNk6nmmRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all pixels below -10 and above 1000-min\n",
        "def remove_outliers(image:np.ndarray):\n",
        "    if np.isnan(image).sum() > 0:\n",
        "        print (\"NAN!\", np.isnan(image).sum() )\n",
        "    min_zero = image[image>-10].min()\n",
        "    image[image<=-10] = min_zero\n",
        "    # do we still have extremal values?\n",
        "    mymax = np.max(image)\n",
        "    mymin = np.min(image)\n",
        "    if mymax-mymin>1000:\n",
        "        print (\"outlier removal:\", mymax)\n",
        "        hi = np.percentile(image, 99).min()\n",
        "        image[image>1000+mymin] = hi\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "yJ_LrKHtS6-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image\n",
        "import base64 # Import the base64 module\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "aTPvkFEqmeN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rvt.vis\n",
        "def preprocessSnippetHillshade(image: np.array):\n",
        "    image = remove_outliers(image)\n",
        "\n",
        "    pixels = rvt.vis.hillshade(\n",
        "        dem=np.squeeze(image), # remove axis...\n",
        "                sun_azimuth=315,\n",
        "                sun_elevation=45,\n",
        "                resolution_x=1.,\n",
        "                resolution_y=1.,\n",
        "                ve_factor=3, # was 2 !!!!!!\n",
        "                #no_data=dem_no_data\n",
        "            ) # output is float32\n",
        "    #pixels = np.nan_to_num(pixels, copy=True, nan=0.0, posinf=None, neginf=None)# remove NaN\n",
        "    pixels = pixels[np.newaxis,...] # and add axis again\n",
        "\n",
        "    return pixels"
      ],
      "metadata": {
        "id": "BWBOoztOS7BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal\n",
        "#import rvt.default\n",
        "import rvt.vis\n",
        "\n",
        "def preprocessSnippetSLRM(image: np.ndarray):\n",
        "    image = remove_outliers(image)\n",
        "    image = rvt.vis.slrm(dem=np.squeeze(image), # remove axis...\n",
        "                radius_cell=10,\n",
        "                ve_factor=1,\n",
        "                no_data=None\n",
        "    )\n",
        "    #image = image[np.newaxis,...] # and add axis again\n",
        "    mymin, mymax = image.min(), image.max()\n",
        "    image = np.interp(image, (mymin, mymax), (0, 255)).astype(np.uint8)\n",
        "    return image"
      ],
      "metadata": {
        "id": "ZWBES7CdS7Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio as rio\n",
        "import PIL\n",
        "def read_hillshade(fpath):\n",
        "  with rio.open(fpath) as t:\n",
        "     img = t.read().squeeze()\n",
        "  img = (preprocessSnippetHillshade(img)*256).astype(np.uint8)\n",
        "  #img = (preprocessSnippetSLRM(img)).astype(np.uint8)\n",
        "  pilimg = PIL.Image.fromarray(img.squeeze()).convert('RGB')\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "L2JEIYlyTA45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to read the images as PIL\n",
        "def read_pil(fpath):\n",
        "  pilimg = PIL.Image.open(fpath)\n",
        "  return pilimg"
      ],
      "metadata": {
        "id": "Bf1ZbZkvg_mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to plot bounding boxes on images\n",
        "def plot_bounding_boxes(img, results):\n",
        "    width, height = img.size\n",
        "    # Create a drawing object\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    fpath='/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'\n",
        "    fontsize = 24\n",
        "    font = ImageFont.truetype(fpath, fontsize)\n",
        "\n",
        "    noun_phrase, prob, bbox = results\n",
        "\n",
        "    if len(bbox) != 4: return # nothing found\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    # Ensure x1 <= x2 and y1 <= y2\n",
        "    x1, x2 = sorted([x1, x2])  # Sort x-coordinates\n",
        "    y1, y2 = sorted([y1, y2])  # Sort y-coordinates\n",
        "\n",
        "    color = 'yellow'\n",
        "    # Draw the bounding box\n",
        "    draw.rectangle(((x1, y1), (x2, y2)), outline=color, width=4)\n",
        "    # Draw the text\n",
        "    draw.text((x1 + 8, y1 + 6), noun_phrase+\" \"+str(prob), fill=color, font=font)"
      ],
      "metadata": {
        "id": "Pw7UfuMZPL47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# process folder"
      ],
      "metadata": {
        "id": "hqncD_OCLXnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sites = sorted(glob('./input/sites/**/*.*', recursive=True))\n",
        "nonsites = sorted(glob('./input/nonsites/**/*.*', recursive=True))\n",
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "hh2zNw_MK6-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4bb026d-e230-4fdf-bfad-449c7bb70c99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment this if you want to try just a small sample of MAX_N for each class\n",
        "import random\n",
        "MAX_Sites = 20\n",
        "MAX_Nonsites = 40\n",
        "\n",
        "#sites = random.sample(sites, MAX_Sites)\n",
        "#nonsites = random.sample(nonsites, MAX_Nonsites)\n",
        "\n",
        "#sites = sites[0:MAX_Sites]\n",
        "#nonsites = nonsites[0:MAX_Nonsites]"
      ],
      "metadata": {
        "id": "X14BfYxwAAHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(sites), len(nonsites)"
      ],
      "metadata": {
        "id": "qEWbSwtB3D1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76aa0e0e-bdc8-49b5-b713-3a6f3987175f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the Gemini output format of a 'Detection'\n",
        "from pydantic import BaseModel, TypeAdapter\n",
        "class Detection(BaseModel):\n",
        "  detection_type: str\n",
        "  probability: float\n",
        "  bbox: list[int]\n",
        "  reason: str"
      ],
      "metadata": {
        "id": "4DpEbr7-qMQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualizeFN = read_hillshade\n",
        "#visualizeFN = read_pil"
      ],
      "metadata": {
        "id": "oGPJt-aXFQpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing all files with GPT"
      ],
      "metadata": {
        "id": "6Sg3gTZv4w_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf output\n",
        "!mkdir output output/FN output/TP output/FP output/TN"
      ],
      "metadata": {
        "id": "I-tCniW3kGXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure parameters\n",
        "#TEMPERATURE = 1.0\n",
        "#TEMPERATURE = 0.7\n",
        "TEMPERATURE = 0.3"
      ],
      "metadata": {
        "id": "mjbCMrfNI_JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "#files = nonsites"
      ],
      "metadata": {
        "id": "dHVx-LLwAk_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = sites + nonsites\n",
        "\n",
        "with open('./output/phrases.txt', 'w') as docfile:\n",
        "  TP, FP, FN, TN = 0, 0, 0, 0\n",
        "  for fpath in tqdm(files):\n",
        "    img = visualizeFN(fpath)\n",
        "    new_size = (img.width // 2, img.height // 2)\n",
        "    img2 = img.copy().resize(new_size) if RESIZE else img\n",
        "\n",
        "    img2.save('./tmp.png')\n",
        "    base64_image = encode_image(\"./tmp.png\")\n",
        "    print('________________________________________________________')\n",
        "\n",
        "    response_format = Detection\n",
        "    for attempt in range(10):\n",
        "      try:\n",
        "        response = client.responses.create(\n",
        "          model = MODEL,\n",
        "          temperature = 0.3,\n",
        "          input=[{\n",
        "             \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"input_text\", \"text\": PROMPT},\n",
        "                {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "          },],}],\n",
        "          text={\n",
        "            \"format\": {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"name\": \"Detection\",\n",
        "              \"schema\": {\n",
        "                  \"type\": \"object\",\n",
        "                  \"properties\": {\n",
        "                      \"detection_type\": {\n",
        "                          \"type\": \"string\"},\n",
        "                      \"probability\": {\n",
        "                          \"type\": \"number\"\n",
        "                      },\n",
        "                      \"bbox\": {\n",
        "                          \"type\": \"array\",\n",
        "                          \"items\": {\n",
        "                              \"type\": \"number\"}\n",
        "                      },\n",
        "                      \"reason\": {\"type\": \"string\"},\n",
        "                  },\n",
        "                  \"required\": [\"detection_type\", \"probability\", \"bbox\", \"reason\"],\n",
        "                  \"additionalProperties\": False\n",
        "              },\n",
        "              \"strict\":True\n",
        "            },},)\n",
        "        if response.output_text:\n",
        "          break # we got through!\n",
        "        #else:\n",
        "        #  print (\"!no output - retry\")\n",
        "      except Exception as e:\n",
        "        print (e);sleep(5);continue\n",
        "      else:\n",
        "        print (\"next attempt\", attempt)\n",
        "\n",
        "    outlist = re.findall(r'({.*?})', response.output_text, re.DOTALL)\n",
        "\n",
        "    FOUND = False\n",
        "    for out in outlist:\n",
        "      try:\n",
        "        ret = json.loads(out)\n",
        "      except json.JSONDecodeError as e:\n",
        "        print(f\"Could not decode JSON object: {out}\")\n",
        "        print(f\"Error: {e}\")\n",
        "      except Exception as e:\n",
        "        print(f\"An unexpected error occurred while processing: {out}\")\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "      if STRICT_RESPONSE_FILTERING:\n",
        "        if any(element in ret['detection_type'].lower() for element in FILTER_KEYWORDS) and float(ret['probability']) >= 0.75:\n",
        "          FOUND = True\n",
        "          plot_bounding_boxes(img, (ret['detection_type'],ret['probability'], ret['bbox']))\n",
        "      else:\n",
        "        p = \"\"\n",
        "\n",
        "    if FOUND:\n",
        "      if 'nonsites' in fpath: FP += 1; p=\"FP\"\n",
        "      else: TP += 1;p=\"TP\"\n",
        "    else:\n",
        "      if 'nonsites' in fpath: TN += 1;p=\"TN\"\n",
        "      else: FN += 1;p=\"FN\"\n",
        "\n",
        "    print (fpath, \"------\", FOUND, \"---\", ret)\n",
        "    display(img.resize(size=(384,384)))\n",
        "\n",
        "    filename = Path(fpath).name\n",
        "    img.save(Path('output')/Path(p)/filename)\n",
        "    docfile.write(\"--- \" + fpath + \":\" + json.dumps(outlist) + os.linesep)\n",
        "    print(\"TP, FP, FN, TN=\", TP, FP, FN, TN, \"(\",TP+FN,\")\")\n",
        "    sleep(1.5)"
      ],
      "metadata": {
        "id": "RDeraYDimtN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F1 = 2*TP/(2*TP+FP+FN)\n",
        "print (TP, FP, FN, TN)\n",
        "print (\"TPR=\", TP/len(sites), \"FPR=\", FP/len(nonsites))\n",
        "print (\"********* F1:\", F1, \" *************\")\n",
        "\n",
        "with open('./output/phrases.txt', 'a') as docfile:\n",
        "  docfile.write(f\"---RESULTS------{os.linesep}\")\n",
        "  docfile.write(f\"TP, FP, FN, TN={TP}, {FP}, {FN}, {TN}{os.linesep}\")\n",
        "  docfile.write(f\"F1={F1}{os.linesep}\")"
      ],
      "metadata": {
        "id": "Ucbfx_IaMgrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export results for download\n",
        "We now open a file download dialog for the output.zip. Simply store the output in your local computer. Done :-)\n",
        "\n",
        "output.zip contains all images with bounding box annotations and a file phrases.txt containing the original response from Gemini.\n",
        "\n"
      ],
      "metadata": {
        "id": "bEriipIF22Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r output.zip output"
      ],
      "metadata": {
        "id": "wJNheETmcYqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colabfiles.download('output.zip')"
      ],
      "metadata": {
        "id": "AE1-K5HR4Za7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHracSEI0kFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}